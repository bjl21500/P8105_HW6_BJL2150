---
title: "P8105_HW6_BJL2150"
author: "Briana Lettsome"
date: "November 27th, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)



library(tidyverse)
library(dplyr)
library(mgcv)
library(modelr)
```

# Problem 1

```{r}
# Reading in and cleaning of the homicide dataset.

homicide_data = read_csv("./homicidedata.csv", na = c("", "NA", "Unknown")) %>%
  janitor::clean_names()
```
  

### Description of the homicide dataset:

The homicide_data  provides information on the numbers of homicides committed within fifty large U.S. cities. Within the dataset, the observations included are the vitcims' first and last name, age, race, city and state that the event transpired in as well as the disposition. The disposition in this context refers to the result of the homicide event. In other words, was the case closed, an arrest made, unsolved, et cetera. 

## Problem 1.1

### Making of the city-state variable and subsequent data manipulation.

```{r}
# Making of the new variable 'city_state'. Also, created a binary variable from
# disposition and named this new observation 'solved',  Where 1 = "Closed by
# arrest" and 0 = "Open/ no arrest" and "Closed without arrest".

# Using this dataframe to count how many states are in the original dataset
# prior to filtering out the 4 city_state observations. 

two_homicide_citystate = homicide_data %>%
  mutate(city_state = str_c(city, ", " , state)) %>%
  mutate(solved = as.numeric(disposition == "Closed by arrest")) %>% 
  count(city_state)  

# This is the working dataframe where the 4 cities were filtered out
# successfully. I will be using this one going forward.

homicide_citystate = homicide_data %>%
  mutate(city_state = str_c(city, ", " , state)) %>% 
  mutate(solved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>%
  select(city_state, victim_race, solved, victim_age, victim_sex, disposition) %>%
  mutate(race = case_when(victim_race == "White" ~ "white",
                          victim_race != "White" ~ "non-white")) %>%
  mutate(victim_age = as.numeric(victim_age)) %>%
  mutate(race = fct_relevel(race, "white")) %>%
  filter(race != "" & victim_age != "")
```

## Problem 1.2

### Focusing only on Baltomre, MD.

```{r}
# Filtering out of Baltimore, MD observation.

baltimore = homicide_citystate %>%
  filter(city_state == "Baltimore, MD")

## Using the 'glm' function to fit a logistic regression model.

glm(solved ~ victim_age + race + victim_sex, data = baltimore, family = binomial()) %>%
  broom::tidy(conf.int = TRUE) %>%
  mutate(OR = exp(estimate)) %>%
  mutate(exp_conf_low = exp(conf.low)) %>%
  mutate(exp_conf_high = exp(conf.high)) %>%
  select(term, OR, exp_conf_low, exp_conf_high, p.value) %>%
  knitr::kable(digits = 3)
```

## Problem 1.3

### Running the glm function on all city_state variables.

```{r}
# Use of the map function to run glm on all city_state variables.

city_state_glm = homicide_citystate %>%
  group_by(city_state) %>%
  nest()%>%
  mutate(models = map(data, ~glm(solved ~ victim_age + race + victim_sex, data = .x, family = binomial())),
models = map(models, broom::tidy, conf.int = TRUE)) %>%
  select(-data) %>% 
  unnest() %>%
  mutate(OR = exp(estimate),
       exp_conf_low = exp(conf.low),
       exp_conf_high = exp(conf.high))

# Made a tidy table showing onnly the OR estimates, confidence intervals and
# p-values.

city_state_glm %>%
  select(city_state, term, OR, exp_conf_low, exp_conf_high, p.value) %>%
  knitr::kable(digits = 3)
```


```{r}
# Specifically selected out the estimates and both confidence intervals columns.
# Additonally, reordered the 'city_state' variable by the 'estimate' variable.

box_city_state = city_state_glm %>%
  filter(term == "racenon-white") %>%
  select(city_state, term, OR, exp_conf_low, exp_conf_high) %>%
  mutate(city_state = forcats::fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  geom_errorbar(aes(ymin = exp_conf_low, ymax = exp_conf_high)) + 
  labs(
    title = "Adjusted OR and 95% CI for Solving Homicides for Non-White/ White",
    x = "City, State",
    y = "Odds Ratio",
    caption = "Figure 1: Data from the Washington Post"
  )

# Making of the boxplot with the inclusion of error bars for low and high CIs.
# Used the 'geoom_errorbar' to complete the latter step. 

box_city_state 
```
  
  Figure 2 illustrates the estimate odds ratios and confidence intervals per city.
Furthermore, these cities were organized by the estimated OR values. 
  At first glance, the solved estimated oddds of solved homicides for non-white
individuals varies throughout the region. According to the figure, Boston, MD had
the smallest odds of solving homicides with the least amount of variability, 
while Tampa, Fl had the highest odds of solving homicides for non-white individuals.
However, with the latter, there was quite a bit of variability observed. The city
with the highest variability in solving homicides for non-white victims compared to
whites was Durham, NC. This conclusion was made based on the wide errors bars
surrounding the OR estimate which corrresponds to the 95% confidence intervals.


# Problem 2

## Problem 2.1

```{r}
# Reading in of birthweight dataset and removing ony observations that are missing, NA or Unknown.

birthweight_data = read_csv("./birthweight.csv", na = c("", "NA", "Unknown")) 
```

### Description of Dataset

The birthweight dataset includes several variables that are proposed to be risk
factors for a child's birthweight. Some of the variables include
gestatioal age in weeks, baby's sex, baby's head cifrcumference, baby's birth
weight, family monthly income, mother's age at delivery and average number of
cigarettes smoked per day during pregnancy.

## Problem 2.2

### Linear Regression model for birthweight.

```{r}
birthweight_clean = birthweight_data %>%
  select(bwt, momage, mrace, smoken, babysex, bhead, blength, gaweeks) 

bw_linear_one = lm(bwt ~ momage + mrace + smoken, data = birthweight_clean)

bw_linear_one %>%
  broom::tidy()
```

### Proposed Model

The model that I propose includes mother's age at delivery, mother's race, and 
average number of cigarettes smoked per day during pregnancy. According to the
Children's Hospital of Philadelphia, there are four risk factors for child's
birthweight. From this, I chose to iclude the aformentioned predictors. In
running a linear regression model, there was an observed statistical
significance for all of the predictors. Therefore, they remained within my hypothesized linear model.

## Problem 2.3

### Add::residuals and add::predictions to plot residuals against fitted values.

```{r}
# Using the add::residuals and add:predictions to observe the output for my linear model.
modelr::add_residuals(birthweight_clean, bw_linear_one)


modelr::add_predictions(birthweight_clean, bw_linear_one)


# Created a scatterplot plotting the residuals against the fitted values.

birthweight_clean %>% 
  modelr::add_residuals(bw_linear_one) %>% 
  modelr::add_predictions(bw_linear_one) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point() +
    labs(
    title = "Modelling of Residuals Against Fitted Values",
    x = "Fitted Values",
    y = "Residuals",
    caption = "Figure 2. Data from birthweight.csv."
  )
```

## Problem 2.3

### Comparison of My Model to the Two Others.

```{r}
# The model that I hypothesized.

bw_linear_one = lm(bwt ~ momage + mrace + smoken, data = birthweight_clean)

# Making of the two comparison models.

length_ges_linear = lm(bwt ~ blength + gaweeks, data = birthweight_clean) 


linear_interaction = lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex,
                        data = birthweight_clean)
```

The below code chunk is used to create the cross-validated predicted error and assess the differences.
```{r}
validation_df = crossv_mc(birthweight_clean, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble))

validation_df = validation_df %>%
  mutate(bw_linear_one = map(train, ~lm(bwt ~ momage + mrace + smoken, data = .x)), 
         length_ges_linear = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
         linear_interaction = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(rmse_bw_linear = map2_dbl(bw_linear_one, test, ~rmse(model = .x, data = .y)),
         rmse_length_ges = map2_dbl(length_ges_linear, test, ~rmse(model = .x, data = .y)),
         rmse_interaction = map2_dbl(linear_interaction, test, ~rmse(model = .x, data = .y))) 

validation_df %>%
  select(.id, starts_with("rmse")) %>%
  gather(key = model, value = rmse, rmse_bw_linear:rmse_interaction) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "Comparison of Cross-Validated Prediction Errors",
    x = "Model",
    y = "Root Mean Square Error",
    caption = "Figure 3. Data from birthweight.csv"
  )
``` 

In looking at Figure 3, the model that I proposed, named rmse_bw_linear, on the 
plot, had the highest root mean square of the three models. Again, the predictors
added to this model are mother's age at delivery, mother's race, and average number
of cigarettes smoked per day during pregnancy. As such, the conclusion can be made
that this model inappropriate.





